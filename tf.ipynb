{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=array([[1., 2., 3., 4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(4,  dtype = float)\n",
    "tf.constant([[1,2,3,4,5,6]], shape = (1,6), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[-0.09487627, -0.71021616, -1.2129327 ],\n",
       "       [-0.4790518 ,  0.95202565,  0.38115796],\n",
       "       [ 0.39500883,  0.11978938,  0.49701583],\n",
       "       [-0.8134479 , -0.6455141 , -0.8509691 ]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal((4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 7 9], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "y = tf.constant([4,5,6])\n",
    "\n",
    "z = tf.add(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tensordot(x,y, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(x*y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((4,3))\n",
    "y = tf.random.normal((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0.29899675,  1.0244724 ,  0.7977205 ],\n",
       "       [ 0.7262494 ,  1.9731113 ,  1.0132442 ],\n",
       "       [-1.7738837 , -1.494336  ,  0.52514845],\n",
       "       [-0.8479573 ,  0.00434151,  2.2959368 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0.29899675,  1.0244724 ,  0.7977205 ],\n",
       "       [ 0.7262494 ,  1.9731113 ,  1.0132442 ],\n",
       "       [-1.7738837 , -1.494336  ,  0.52514845],\n",
       "       [-0.8479573 ,  0.00434151,  2.2959368 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.range(9)\n",
    "x = tf.reshape(x, (3,3))\n",
    "x = tf.transpose(x, perm=[1,0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequntial and Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (28,28,1)),\n",
    "        layers.Conv2D(32, 3, activation='relu',),\n",
    "        layers.MaxPool2D(pool_size=(2)),\n",
    "        layers.Conv2D(64, 3, activation='relu',),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(128, 3, activation='relu',),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation= 'relu'),\n",
    "        layers.Dense(10)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 64, epochs = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 - 0s - loss: 5.4916 - accuracy: 0.1010 - 164ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.491640090942383, 0.10100000351667404]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n",
    "xtrain = xtrain.astype(\"float32\") /255.0\n",
    "xtest = xtest.astype(\"float32\") /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (32,32,3)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu',),\n",
    "        layers.MaxPool2D(pool_size=(2,2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu',),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu',),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 5, padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Conv2D(128, 3,padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs = inputs, outputs= outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 88s - loss: 1.5419 - accuracy: 0.4641 - 88s/epoch - 112ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 87s - loss: 1.5213 - accuracy: 0.4728 - 87s/epoch - 112ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 88s - loss: 1.5068 - accuracy: 0.4773 - 88s/epoch - 112ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 92s - loss: 1.5063 - accuracy: 0.4766 - 92s/epoch - 117ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 92s - loss: 1.5049 - accuracy: 0.4773 - 92s/epoch - 117ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 88s - loss: 1.4907 - accuracy: 0.4801 - 88s/epoch - 112ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 88s - loss: 1.4843 - accuracy: 0.4852 - 88s/epoch - 113ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 88s - loss: 1.4903 - accuracy: 0.4809 - 88s/epoch - 113ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 90s - loss: 1.4864 - accuracy: 0.4834 - 90s/epoch - 115ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 90s - loss: 1.4801 - accuracy: 0.4841 - 90s/epoch - 116ms/step\n",
      "157/157 - 4s - loss: 1.1956 - accuracy: 0.6666 - 4s/epoch - 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.195557713508606, 0.6665999889373779]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adagrad(learning_rate=3e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(xtrain, ytrain, batch_size=64, epochs=10, verbose=2)\n",
    "\n",
    "model.evaluate(xtest, ytest, batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, GRUS, LSTM and Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 85s - loss: 0.2490 - accuracy: 0.9233 - 85s/epoch - 90ms/step\n",
      "Epoch 2/10\n",
      "938/938 - 84s - loss: 0.1346 - accuracy: 0.9594 - 84s/epoch - 89ms/step\n",
      "Epoch 3/10\n",
      "938/938 - 81s - loss: 0.1079 - accuracy: 0.9671 - 81s/epoch - 86ms/step\n",
      "Epoch 4/10\n",
      "938/938 - 71s - loss: 0.0952 - accuracy: 0.9709 - 71s/epoch - 75ms/step\n",
      "Epoch 5/10\n",
      "938/938 - 80s - loss: 0.0789 - accuracy: 0.9760 - 80s/epoch - 85ms/step\n",
      "Epoch 6/10\n",
      "938/938 - 74s - loss: 0.0740 - accuracy: 0.9774 - 74s/epoch - 79ms/step\n",
      "Epoch 7/10\n",
      "938/938 - 71s - loss: 0.0723 - accuracy: 0.9776 - 71s/epoch - 75ms/step\n",
      "Epoch 8/10\n",
      "938/938 - 71s - loss: 0.0614 - accuracy: 0.9815 - 71s/epoch - 76ms/step\n",
      "Epoch 9/10\n",
      "938/938 - 71s - loss: 0.0624 - accuracy: 0.9808 - 71s/epoch - 75ms/step\n",
      "Epoch 10/10\n",
      "938/938 - 71s - loss: 0.0555 - accuracy: 0.9829 - 71s/epoch - 75ms/step\n",
      "157/157 - 3s - loss: 0.0577 - accuracy: 0.9826 - 3s/epoch - 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05767861753702164, 0.9825999736785889]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(None, 28)))\n",
    "model.add(\n",
    "    layers.SimpleRNN(512, return_sequences= True, activation = 'tanh')\n",
    ")\n",
    "model.add(layers.SimpleRNN(512, activation='tanh'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate= 3e-4),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size= 64, epochs= 10, verbose = 2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 75s - loss: 0.4426 - accuracy: 0.8512 - 75s/epoch - 80ms/step\n",
      "Epoch 2/10\n",
      "938/938 - 75s - loss: 0.1146 - accuracy: 0.9635 - 75s/epoch - 80ms/step\n",
      "Epoch 3/10\n",
      "938/938 - 71s - loss: 0.0714 - accuracy: 0.9776 - 71s/epoch - 76ms/step\n",
      "Epoch 4/10\n",
      "938/938 - 74s - loss: 0.0531 - accuracy: 0.9833 - 74s/epoch - 79ms/step\n",
      "Epoch 5/10\n",
      "938/938 - 74s - loss: 0.0422 - accuracy: 0.9865 - 74s/epoch - 79ms/step\n",
      "Epoch 6/10\n",
      "938/938 - 71s - loss: 0.0347 - accuracy: 0.9895 - 71s/epoch - 76ms/step\n",
      "Epoch 7/10\n",
      "938/938 - 63s - loss: 0.0288 - accuracy: 0.9909 - 63s/epoch - 67ms/step\n",
      "Epoch 8/10\n",
      "938/938 - 61s - loss: 0.0253 - accuracy: 0.9916 - 61s/epoch - 65ms/step\n",
      "Epoch 9/10\n",
      "938/938 - 65s - loss: 0.0205 - accuracy: 0.9934 - 65s/epoch - 69ms/step\n",
      "Epoch 10/10\n",
      "938/938 - 63s - loss: 0.0173 - accuracy: 0.9944 - 63s/epoch - 67ms/step\n",
      "157/157 - 4s - loss: 0.0413 - accuracy: 0.9883 - 4s/epoch - 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04133369401097298, 0.9883000254631042]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape = (None, 28)))\n",
    "model.add(\n",
    "    layers.GRU(256, return_sequences = True, activation = 'tanh')\n",
    ")\n",
    "model.add(layers.GRU(256, activation = 'tanh'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs =10, verbose =2)\n",
    "model.evaluate(x_test, y_test, batch_size =64, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 86s - loss: 0.5005 - accuracy: 0.8340 - 86s/epoch - 91ms/step\n",
      "Epoch 2/10\n",
      "938/938 - 83s - loss: 0.1118 - accuracy: 0.9662 - 83s/epoch - 88ms/step\n",
      "Epoch 3/10\n",
      "938/938 - 83s - loss: 0.0743 - accuracy: 0.9775 - 83s/epoch - 89ms/step\n",
      "Epoch 4/10\n",
      "938/938 - 78s - loss: 0.0551 - accuracy: 0.9823 - 78s/epoch - 84ms/step\n",
      "Epoch 5/10\n",
      "938/938 - 78s - loss: 0.0445 - accuracy: 0.9865 - 78s/epoch - 83ms/step\n",
      "Epoch 6/10\n",
      "938/938 - 80s - loss: 0.0385 - accuracy: 0.9885 - 80s/epoch - 86ms/step\n",
      "Epoch 7/10\n",
      "938/938 - 76s - loss: 0.0308 - accuracy: 0.9903 - 76s/epoch - 81ms/step\n",
      "Epoch 8/10\n",
      "938/938 - 76s - loss: 0.0305 - accuracy: 0.9902 - 76s/epoch - 82ms/step\n",
      "Epoch 9/10\n",
      "938/938 - 73s - loss: 0.0249 - accuracy: 0.9920 - 73s/epoch - 78ms/step\n",
      "Epoch 10/10\n",
      "938/938 - 73s - loss: 0.0216 - accuracy: 0.9932 - 73s/epoch - 78ms/step\n",
      "157/157 - 4s - loss: 0.0469 - accuracy: 0.9864 - 4s/epoch - 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04690316691994667, 0.9864000082015991]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape = (None, 28)))\n",
    "model.add(\n",
    "    layers.LSTM(256, return_sequences = True, activation = 'tanh')\n",
    ")\n",
    "model.add(layers.LSTM(256, activation = 'tanh'))\n",
    "model.add(layers.Dense(64))\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits =True),\n",
    "    optimizer= keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 64, epochs = 10, verbose = 2)\n",
    "model.evaluate(x_test, y_test, batch_size =64, verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 244s - loss: 0.2737 - accuracy: 0.9102 - 244s/epoch - 260ms/step\n",
      "Epoch 2/10\n",
      "938/938 - 236s - loss: 0.0775 - accuracy: 0.9765 - 236s/epoch - 251ms/step\n",
      "Epoch 3/10\n",
      "938/938 - 235s - loss: 0.0544 - accuracy: 0.9829 - 235s/epoch - 251ms/step\n",
      "Epoch 4/10\n",
      "938/938 - 269s - loss: 0.0433 - accuracy: 0.9868 - 269s/epoch - 287ms/step\n",
      "Epoch 5/10\n",
      "938/938 - 273s - loss: 0.0360 - accuracy: 0.9890 - 273s/epoch - 291ms/step\n",
      "Epoch 6/10\n",
      "938/938 - 253s - loss: 0.0288 - accuracy: 0.9910 - 253s/epoch - 270ms/step\n",
      "Epoch 7/10\n",
      "938/938 - 243s - loss: 0.0248 - accuracy: 0.9924 - 243s/epoch - 259ms/step\n",
      "Epoch 8/10\n",
      "938/938 - 243s - loss: 0.0215 - accuracy: 0.9932 - 243s/epoch - 259ms/step\n",
      "Epoch 9/10\n",
      "938/938 - 243s - loss: 0.0188 - accuracy: 0.9941 - 243s/epoch - 259ms/step\n",
      "Epoch 10/10\n",
      "938/938 - 244s - loss: 0.0149 - accuracy: 0.9950 - 244s/epoch - 260ms/step\n",
      "157/157 - 13s - loss: 0.0442 - accuracy: 0.9880 - 13s/epoch - 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04417228326201439, 0.9879999756813049]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape = (None, 28)))\n",
    "model.add(\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(256, return_sequences = True, activation = 'tanh')\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(256, activation = 'tanh')\n",
    "    )\n",
    ")\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size = 64, epochs = 10, verbose = 2)\n",
    "model.evaluate(x_test, y_test, batch_size =64, verbose =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API for Multilabel multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "WEIGHT_DECAY = 0.001\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"mnist_multi_digit_/train.csv\")\n",
    "test_df = pd.read_csv(\"mnist_multi_digit_/test.csv\")\n",
    "\n",
    "train_images = os.getcwd() + \"/mnist_multi_digit_/\" + \"train_images/\" + train_df.iloc[:, 0].values\n",
    "test_images = os.getcwd() + \"/mnist_multi_digit_/\" + \"test_images/\" + test_df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df.iloc[:, 1:].values\n",
    "test_labels = test_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
    "\n",
    "    labels = {\"first_number\": label[0], \"second_number\": label[1]}\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=len(train_labels))\n",
    "    .map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = (\n",
    "    test_dataset.shuffle(buffer_size=len(test_labels))\n",
    "    .map(read_image)\n",
    "    .batch(batch_size = BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 - 728s - loss: 1.7751 - first_number_loss: 0.8600 - second_number_loss: 0.8300 - first_number_accuracy: 0.6999 - second_number_accuracy: 0.7075 - 728s/epoch - 728ms/step\n",
      "Epoch 2/5\n",
      "1000/1000 - 719s - loss: 0.5556 - first_number_loss: 0.2483 - second_number_loss: 0.2406 - first_number_accuracy: 0.9195 - second_number_accuracy: 0.9222 - 719s/epoch - 719ms/step\n",
      "Epoch 3/5\n",
      "1000/1000 - 731s - loss: 0.3561 - first_number_loss: 0.1514 - second_number_loss: 0.1462 - first_number_accuracy: 0.9520 - second_number_accuracy: 0.9538 - 731s/epoch - 731ms/step\n",
      "Epoch 4/5\n",
      "1000/1000 - 777s - loss: 0.2792 - first_number_loss: 0.1146 - second_number_loss: 0.1111 - first_number_accuracy: 0.9636 - second_number_accuracy: 0.9640 - 777s/epoch - 777ms/step\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape = (64,64,1))\n",
    "x = layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.Conv2D(\n",
    "    64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY)\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(\n",
    "    64, \n",
    "    3,\n",
    "    activation = 'relu',\n",
    "    kernel_regularizer=regularizers.l2(WEIGHT_DECAY)\n",
    ")(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output1 = layers.Dense(10, activation='softmax', name='first_number')(x)\n",
    "output2 = layers.Dense(10, activation='softmax', name='second_number')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[output1, output2])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n",
    "    loss=[\n",
    "        keras.losses.SparseCategoricalCrossentropy(),\n",
    "        keras.losses.SparseCategoricalCrossentropy(),\n",
    "    ],\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(train_dataset, epochs=5, verbose=2)\n",
    "model.evaluate(test_dataset, verbose=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
